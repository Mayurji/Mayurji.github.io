## Data Structures - Deque, Priority Queue & Master Theorem

In previous blog post, we discussed [Stack, Queue and Heap](https://mayurji.github.io/data-structure-algorithms/2021-01-23-DSA_2) and in continuation with that, we'll discuss variants of Queue and how heap acts as best data structure to perform priority queue and what is master theorem & why its used.

### Deque

Deque is also known as Double-Ended Queue. In normal queue, we perform insertion on rear side and deletion on front side of the queue following FIFO (First In First Out), in **deque**, we can perform both insertion and deletion on both the sides of the queue.

<center>
<img src="{{site.url}}/assets/images/dsa/pankaj-patel-_SgRNwAVNKw-unsplash.jpg" style="zoom: 5%; background-color:#DCDCDC;" width="100%" height=auto/><br>
</center>

**Various operations in Deque**

* Inserting at the front of the queue
* Deletion from the front of the queue
* Inserting at the rear of the queue
* Deletion from the rear of the queue
* IsEmpty
* isFull

**Simple Implementation of Deque using List**

```python
# Deque implementaion in python

class Deque:
    def __init__(self):
        self.items = []

    def isEmpty(self):
        return self.items == []

    def addRear(self, item):
        self.items.append(item)

    def addFront(self, item):
        self.items.insert(0, item)

    def removeFront(self):
        return self.items.pop()

    def removeRear(self):
        return self.items.pop(0)

    def size(self):
        return len(self.items)

"""
d = Deque()
d.addFront(10)
d.addFront(20)
d.addFront(30)

d.items
`[30, 20, 10]`

d.removeRear()
`30`

d.addRear(56)
d.items
`[20, 10, 56]`
"""
```

**Time Complexity**

The time complexity of all the above operations is constant i.e. `O(1)`.

**Applications**

1. In undo operations on software.
2. To store history in browsers.

### Priority Queue

Priority Queue is a special type of queue, where each element is associated with priority and served according to its priority. If elements with the same priority occur, they are served according to their order in the queue.

Image(priority Queue)

*For example, The element with the highest value is considered as the highest priority element. However, in other cases, we can assume the element with the lowest value as the highest priority element. In other cases, we can set priorities according to our needs.*

We can implement priority queue using array, linked list, heap data structure. And most efficient implementation of Priority Queue is done by heap data structure like max heap and min heap.

**Code Implementation of Priority Queue Using Heap Data Structure**

*I've mentioned about [min heap in the previous blog post](https://mayurji.github.io/data-structure-algorithms/2021-01-23-DSA_2) refer the code.*

Basics operation of priority queue includes Insertion, deletion, peeking elements.

Priority queue depends on the how the priority is assigned. If priority is assigned to max values then we use **max-heap** and similar if priority smallest value then we create **min-heap**.

**Applications**

- Dijkstra's algorithm
- for data compression in Huffman code

### Master Theorem

In Divide and Conquer strategy, we use recursion to solve the larger problem by dividing it into smaller problems. Master theorem is used for solving such recursive relations. It is used for calculating the time complexity of recurrence relations.

In divide and conquer, any problem/tasks has two parts:

* reducible problem
* Irreducible problem

**Master Theorem for Dividing Function**
$$
\\
General\ Form:\ T(n) = a \ T(n/b) + f(n) 
\\
where, \ a \ge 1\ and\ b > 1\ and\ f(n)= \theta(n^k\ log^p n)
$$
**T(n/b) is a reducible problem**, where *n* is the input size of the problem, which is reduced by *b*, where b>1.  *a* is the number of sub-problems in the recursion to be solved. **f(n)** is a non-reducible problem, which is solved outside the recursion, like dividing the problem and merging the solution of all smaller problem.
$$
To\ find\ time\ complexity\ of\ dividing\ function-\ Find\ log_b ^a\ and\ k
\\
Case 1:\ log_b ^a >\ k,\ then\ \theta(n^{log_b^a}).
\\
Solving\ T(n) = 8\ T(n/2)\ + n^1
\\
Here, a =8,\ b=2,\ k=1\ and\ log_2 ^8 = 3
\\
log_b^a\ > k,\ so\ \theta(n^3)\ is\ the\ time\ complexity!
$$
 

Similar to above cases, there are various cases based on values of $$ log_b^a\ and\ k$$. I highly recommend videos from [**Abdul Bari's Youtube channel for all cases**]() where he provides the shortcuts for each case.

**Master Theorem for Decreasing Function**
$$
General\ Form:\ T(n) = a \ T(n-b) + f(n) \\where, \ a > 0,\ \ b > 0,\ k\ \ge\ 0\ and\ f(n)= \theta(n^k).
\\
Case1:\ a=1,\ O(n* f(n))
\\
Case2:\ a>1,\ O(n^k\ a^{n/b})
\\
Case3:\ a<1,\ O(n^k)
$$
**Sample decreasing function**
$$
T(n) = {1,\  n=0}
\\
T(n) = 2T(n-1)+1,\ n>0
\\
Here,\ a=2,\ b=1,\ and\ k=0.\ 
\\
Time\ complexity\ is\ O(2^n)\ based\ on\ case2
$$
I've introduced only the base cases for master theorem, before that we've seen priority queue whose best implementation is done using **heap data structure** and Double-ended queue and its implementation.

### Reference

[Abdul Bari's Videos on Master Theorem](https://www.youtube.com/channel/UCZCFT11CWBi3MHNlGf019nw)

[Previous Blog For Heap Implementation](https://mayurji.github.io/data-structure-algorithms/2021-01-23-DSA_2)

[Programiz](https://www.programiz.com/dsa/priority-queue)
